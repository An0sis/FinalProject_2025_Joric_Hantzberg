{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input\n",
    "from tensorflow.keras import layers, Model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data directory\n",
    "data_path = \"../data/KuaiRec/data/\"\n",
    "\n",
    "# Load all required datasets\n",
    "print(\"Loading big matrix...\")\n",
    "big_matrix = pd.read_csv(data_path + \"big_matrix.csv\")\n",
    "print(\"Loading small matrix...\")\n",
    "small_matrix = pd.read_csv(data_path + \"small_matrix.csv\")\n",
    "print(\"Loading social network...\")\n",
    "social_network = pd.read_csv(data_path + \"social_network.csv\")\n",
    "print(\"Loading item features...\")\n",
    "item_categories = pd.read_csv(data_path + \"item_categories.csv\")\n",
    "item_categories[\"feat\"] = item_categories[\"feat\"].map(eval)\n",
    "print(\"Loading user features...\")\n",
    "user_features = pd.read_csv(data_path + \"user_features.csv\")\n",
    "print(\"Loading items' daily features...\")\n",
    "item_daily_features = pd.read_csv(data_path + \"item_daily_features.csv\")\n",
    "print(\"All data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f53131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the interaction matrix for training and testing\n",
    "interaction_matrix = big_matrix[[\"user_id\", \"video_id\", \"watch_ratio\"]]\n",
    "interaction_matrix = interaction_matrix[interaction_matrix['watch_ratio'] <= 2]\n",
    "interaction_matrix['watch_ratio'] = (interaction_matrix['watch_ratio'] - interaction_matrix['watch_ratio'].min()) / (interaction_matrix['watch_ratio'].max() - interaction_matrix['watch_ratio'].min())\n",
    "\n",
    "test_matrix = small_matrix[[\"user_id\", \"video_id\", \"watch_ratio\"]]\n",
    "test_matrix = test_matrix[test_matrix['watch_ratio'] <= 2]\n",
    "test_matrix['watch_ratio'] = (test_matrix['watch_ratio'] - test_matrix['watch_ratio'].min()) / (test_matrix['watch_ratio'].max() - test_matrix['watch_ratio'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c576be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare user features (one-hot encoded, fill missing, shift indices)\n",
    "onehot_cols = [f\"onehot_feat{i}\" for i in range(18)]\n",
    "users = user_features[[\"user_id\"] + onehot_cols].copy()\n",
    "\n",
    "users[onehot_cols] = users[onehot_cols].fillna(-1).astype(int) + 1\n",
    "users[\"user_id\"] = users[\"user_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e79ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to shift and pad tag lists for consistent input length\n",
    "def shift_and_pad(tags, max_len=31):\n",
    "    shifted = [tag + 1 for tag in tags]\n",
    "    padded = shifted[:max_len] + [0] * (max_len - len(shifted))\n",
    "    return padded\n",
    "\n",
    "# Aggregate daily features for each video and merge with static features\n",
    "agg_funcs = {\n",
    "    \"author_id\": \"last\",\n",
    "    \"video_duration\": \"last\",\n",
    "    \"play_progress\": \"mean\",\n",
    "    \"video_tag_id\": \"last\",\n",
    "    \"play_cnt\": \"sum\",\n",
    "    \"like_cnt\": \"sum\",\n",
    "    \"share_cnt\": \"sum\",\n",
    "    \"comment_cnt\": \"sum\"\n",
    "}\n",
    "videos = item_daily_features.groupby(\"video_id\").agg(agg_funcs)\n",
    "videos = videos.merge(item_categories, on=\"video_id\", how=\"left\").set_index(\"video_id\")\n",
    "\n",
    "videos = videos[videos[\"video_duration\"] <= 20000]\n",
    "videos[\"video_duration\"] = videos[\"video_duration\"].fillna(0).astype(int)\n",
    "\n",
    "videos[\"video_tag_id\"] = videos[\"video_tag_id\"].fillna(-1).astype(int) + 1\n",
    "\n",
    "videos[\"feat\"] = videos[\"feat\"].apply(shift_and_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8a0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory by deleting large unused dataframes\n",
    "del small_matrix\n",
    "del big_matrix\n",
    "del item_daily_features\n",
    "del item_categories\n",
    "del user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28881ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "EMBEDDING_DIM = 64\n",
    "TAG_EMBED_DIM = 64\n",
    "NUM_TAGS = 31\n",
    "USER_VOCAB_SIZE = [2, 8, 30, 1076, 12, 10, 3, 47, 340, 7, 5, 3, 2, 2, 2, 2, 2, 2]\n",
    "BATCH_SIZE = 256\n",
    "NB_EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_AUTHOR_ID = videos[\"author_id\"].max()\n",
    "MAX_TAG_ID = videos[\"video_tag_id\"].max() + 1\n",
    "\n",
    "TOP_K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9418113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User tower model definition\n",
    "class UserTower(Model):\n",
    "    def __init__(self):\n",
    "        super(UserTower, self).__init__()\n",
    "        self.embedding_layers = []\n",
    "        # Embedding layers for each categorical user feature\n",
    "        for vocab_size in USER_VOCAB_SIZE:\n",
    "            self.embedding_layers.append(Embedding(input_dim=vocab_size + 1, output_dim=TAG_EMBED_DIM))\n",
    "        # Dense layers for user representation\n",
    "        self.value_layers = tf.keras.Sequential([\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(EMBEDDING_DIM)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_embeds = []\n",
    "        for i in range(inputs.shape[1]):\n",
    "            input_i = inputs[:, i]\n",
    "            embed = self.embedding_layers[i](input_i)\n",
    "            user_embeds.append(embed)\n",
    "            \n",
    "        user_concat = tf.concat(user_embeds, axis=-1)\n",
    "        return self.value_layers(user_concat)\n",
    "\n",
    "# Video tower model definition\n",
    "class VideoTower(Model):\n",
    "    def __init__(self):\n",
    "        super(VideoTower, self).__init__()\n",
    "        # Embedding for author and tag IDs\n",
    "        self.author_manager = tf.keras.Sequential([\n",
    "            Input(shape=(), dtype=tf.int32, name=\"video_tag_id\"),\n",
    "            Embedding(input_dim=MAX_AUTHOR_ID + 1, output_dim=TAG_EMBED_DIM)\n",
    "        ])\n",
    "        \n",
    "        self.tag_id_manager = tf.keras.Sequential([\n",
    "            Input(shape=(), dtype=tf.int32, name=\"author_id\"),\n",
    "            Embedding(input_dim=MAX_TAG_ID + 1, output_dim=TAG_EMBED_DIM)\n",
    "        ])\n",
    "        \n",
    "        # Embedding for tag list\n",
    "        self.tag_manager = tf.keras.Sequential([\n",
    "            Embedding(input_dim=NUM_TAGS + 1, output_dim=TAG_EMBED_DIM, mask_zero=True),\n",
    "            layers.GlobalAveragePooling1D()\n",
    "        ])\n",
    "        \n",
    "        # Dense layers for numerical features\n",
    "        self.value_layers = tf.keras.Sequential([\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(EMBEDDING_DIM)\n",
    "        ])\n",
    "        self.last = Dense(EMBEDDING_DIM)\n",
    "        \n",
    "    def call(self, tag_input, author_id, tag_id, numeric_input):\n",
    "        tag_id_vector = self.tag_id_manager(tag_id)\n",
    "        author_vector = self.author_manager(author_id)\n",
    "        tag_vector = self.tag_manager(tag_input)\n",
    "        numeric_vector = self.value_layers(numeric_input)\n",
    "        \n",
    "        combined = tf.concat([tag_vector, numeric_vector, tag_id_vector, author_vector], axis=1)\n",
    "        return self.last(combined)\n",
    "\n",
    "# Two-tower fusion model\n",
    "class TwoTowerModel(Model):\n",
    "    def __init__(self, user_tower, video_tower):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        self.user_tower = user_tower\n",
    "        self.video_tower = video_tower\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_input, video_tag_input, video_author_input, video_tag_id_input, video_continuous_input = inputs\n",
    "        user_emb = self.user_tower(user_input)\n",
    "        video_emb = self.video_tower(video_tag_input, video_author_input, video_tag_id_input, video_continuous_input)\n",
    "        user_emb = tf.linalg.l2_normalize(user_emb, axis=1)\n",
    "        video_emb = tf.linalg.l2_normalize(video_emb, axis=1)\n",
    "        dot_product = layers.Dot(axes=1)([user_emb, video_emb])\n",
    "        \n",
    "        return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee55f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper to create tf.data.Dataset for training or evaluation\n",
    "def create_dataset(interaction_matrix):\n",
    "    interaction_matrix = interaction_matrix.merge(users, on=\"user_id\", how=\"left\")\n",
    "    interaction_matrix = interaction_matrix.merge(videos, on=\"video_id\", how=\"left\")\n",
    "    interaction_matrix = interaction_matrix.dropna()\n",
    "    \n",
    "    user_data = interaction_matrix[[f\"onehot_feat{i}\" for i in range(18)]].values\n",
    "    video_tag_data = np.array(interaction_matrix[\"feat\"].tolist(), dtype=np.int32)\n",
    "    video_author_id = interaction_matrix[\"author_id\"].values\n",
    "    video_tag_id = interaction_matrix[\"video_tag_id\"].values\n",
    "    video_continuous_data = interaction_matrix[[\"video_duration\", \"play_progress\"]].values\n",
    "    labels = interaction_matrix[\"watch_ratio\"].values\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((user_data, video_tag_data, video_author_id, video_tag_id, video_continuous_data), labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(user_data))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "dataset_train = create_dataset(interaction_matrix)\n",
    "\n",
    "# Instantiate and compile the two-tower model\n",
    "user_tower = UserTower()\n",
    "video_tower = VideoTower()\n",
    "tower_model = TwoTowerModel(user_tower=user_tower, video_tower=video_tower)\n",
    "tower_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = tower_model.fit(\n",
    "    dataset_train,\n",
    "    epochs=NB_EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e239c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set and plot loss curves\n",
    "dataset_test = create_dataset(test_matrix)\n",
    "loss, mae = tower_model.evaluate(dataset_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4873064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for ranking metrics\n",
    "def prepare_dataset_for_metrics(matrix):\n",
    "    matrix = matrix.merge(users, on=\"user_id\", how=\"left\")\n",
    "    matrix = matrix.merge(videos, on=\"video_id\", how=\"left\")\n",
    "    matrix = matrix.dropna()\n",
    "    \n",
    "    user_data = matrix[[f\"onehot_feat{i}\" for i in range(18)]].values\n",
    "    video_tag_data = np.array(matrix[\"feat\"].tolist(), dtype=np.int32)\n",
    "    video_author_id = matrix[\"author_id\"].values\n",
    "    video_tag_id = matrix[\"video_tag_id\"].values\n",
    "    video_continuous_data = matrix[[\"video_duration\", \"play_progress\"]].values\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((user_data, video_tag_data, video_author_id, video_tag_id, video_continuous_data), matrix[\"watch_ratio\"].values))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset, matrix\n",
    "\n",
    "metrics_dataset, matrix = prepare_dataset_for_metrics(test_matrix)\n",
    "predictions = tower_model.predict(metrics_dataset, verbose=1)\n",
    "matrix[\"predictions\"] = predictions\n",
    "\n",
    "# Helper functions to get top predicted and real items per user\n",
    "def get_top_items(group):\n",
    "    return group.sort_values(\"predictions\", ascending=False)[\"video_id\"].tolist()\n",
    "def get_real_top_items(group):\n",
    "    return group.sort_values(\"watch_ratio\", ascending=False)[\"video_id\"].tolist()\n",
    "\n",
    "matrix = (\n",
    "    matrix.groupby(\"user_id\")\n",
    "    .apply(lambda group: pd.Series({\n",
    "        \"predicted\": get_top_items(group),\n",
    "        \"real\": get_real_top_items(group)\n",
    "    }))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cb08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Ranking Metrics Section\n",
    "# =======================\n",
    "\n",
    "# Build dictionaries for predictions and ground truth\n",
    "predictions_dict = matrix.set_index(\"user_id\")[\"predicted\"].to_dict()\n",
    "ground_truth_dict = matrix.set_index(\"user_id\")[\"real\"].to_dict()\n",
    "\n",
    "# Precision@K\n",
    "def precision_at_k(predictions, ground_truth):\n",
    "    precisions = []\n",
    "    for user, recommended_items in predictions.items():\n",
    "        relevant_items = set(ground_truth.get(user, []))\n",
    "        top_k = recommended_items[:TOP_K]\n",
    "        hit_count = len(set(top_k) & relevant_items)\n",
    "        precisions.append(hit_count / TOP_K)\n",
    "    return sum(precisions) / len(precisions)\n",
    "\n",
    "# Recall@K\n",
    "def recall_at_k(predictions, ground_truth):\n",
    "    recalls = []\n",
    "    for user, recommended_items in predictions.items():\n",
    "        relevant_items = set(ground_truth.get(user, []))\n",
    "        if not relevant_items:\n",
    "            continue\n",
    "        top_k = recommended_items[:TOP_K]\n",
    "        hit_count = len(set(top_k) & relevant_items)\n",
    "        recalls.append(hit_count / len(relevant_items))\n",
    "    return sum(recalls) / len(recalls)\n",
    "\n",
    "# NDCG@K\n",
    "def ndcg_at_k(predictions, ground_truth):\n",
    "    def dcg(recommended, relevant):\n",
    "        return sum(1 / math.log2(i + 2) for i, item in enumerate(recommended) if item in relevant)\n",
    "    ndcgs = []\n",
    "    for user, recommended_items in predictions.items():\n",
    "        relevant_items = ground_truth.get(user, set())\n",
    "        top_k = recommended_items[:TOP_K]\n",
    "        ideal_dcg = dcg(sorted(relevant_items, key=lambda x: 1, reverse=True)[:TOP_K], relevant_items)\n",
    "        actual_dcg = dcg(top_k, relevant_items)\n",
    "        if ideal_dcg == 0:\n",
    "            continue\n",
    "        ndcgs.append(actual_dcg / ideal_dcg)\n",
    "    return sum(ndcgs) / len(ndcgs)\n",
    "\n",
    "# MAP@K\n",
    "def average_precision_at_k(recommended, relevant):\n",
    "    hits = 0\n",
    "    sum_precisions = 0\n",
    "    for i, item in enumerate(recommended[:TOP_K]):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    return sum_precisions / min(len(relevant), TOP_K) if relevant else 0\n",
    "\n",
    "def map_at_k(predictions, ground_truth):\n",
    "    average_precisions = []\n",
    "    for user, recommended_items in predictions.items():\n",
    "        relevant_items = ground_truth.get(user, set())\n",
    "        ap = average_precision_at_k(recommended_items, relevant_items)\n",
    "        average_precisions.append(ap)\n",
    "    return sum(average_precisions) / len(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3086ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Evaluate metrics at different K\n",
    "# =======================\n",
    "\n",
    "TOP_K = 1\n",
    "print(\"Precision@K:\", precision_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"Recall@K:\", recall_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"NDCG@K:\", ndcg_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"MAP@K:\", map_at_k(predictions_dict, ground_truth_dict))\n",
    "\n",
    "TOP_K = 10\n",
    "print(\"Precision@K:\", precision_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"Recall@K:\", recall_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"NDCG@K:\", ndcg_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"MAP@K:\", map_at_k(predictions_dict, ground_truth_dict))\n",
    "\n",
    "TOP_K = 100\n",
    "print(\"Precision@K:\", precision_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"Recall@K:\", recall_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"NDCG@K:\", ndcg_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"MAP@K:\", map_at_k(predictions_dict, ground_truth_dict))\n",
    "\n",
    "TOP_K = 500\n",
    "print(\"Precision@K:\", precision_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"Recall@K:\", recall_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"NDCG@K:\", ndcg_at_k(predictions_dict, ground_truth_dict))\n",
    "print(\"MAP@K:\", map_at_k(predictions_dict, ground_truth_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418cde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get top-k recommendations for a user\n",
    "def get_top_k_user(user_id, k):\n",
    "    return predictions_dict[user_id][:k]\n",
    "\n",
    "print(get_top_k_user(14, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
